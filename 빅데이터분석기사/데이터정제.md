---
title: 데이터 정제
layout: default
parent: 빅데이터_탐색
grand_parent: 데이터분석기사
nav_order: 1
---
<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">1. 데이터 정제</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.결측값(Null)](#chapter-1)<br>
- [2.이상값(Outlier)](#chapter-2)<br>


### **1-1. 결측값(Null)** <a id="chapter-1"></a>

1. 종류

|결측 유형|설명|
|:------|:--|
|완전 무작위 결측<br>(Missing Completely At Random)|난수처럼 경향성 없이 완전 무작위로 결측값 발생|
|무작위 결측<br>(Missing At Random)|경향성을 띄고 있으면서 무작위로 결측값 발생| 
|비 무작위 결측<br>(Missing Not At Random)|경향성을 띄고 있는 결측값 발생|


2. 처리 방법 (제거? or 대체?)

- 완전 분석법(Completes Analysis)
  - 결측값이 존재하는 행 단순 삭제 
  - 삭제 되는 행이 많아지면 데이터 분석에 문제가 생김(데이터 수집 단계에서 문제가 있는 것) 
<br>
  
- 평균(중앙값) 대체볍(Mean Imputation)
  - 무작위 결측이 전제
  - 평균(중앙값)으로 결측값을 대체 (데이터가 많을 시에는 대세에 영향이 없음)
<br>

- 단순 확률 대체법(Single Stochastic Imputation)
  - 특정 집단에 대해서 결측값을 평균 값 등으로 대체
  - Ex) 남자 평균, 여자 평균



### **1-2. 이상값(Outlier)** <a id="chapter-2"></a>

{: .highlight }
이상값 몇 개가 결과를 크게 **왜곡**시킬 수 있다.

1. 이상값(Outlier) 진단방법
   - **사분위수**를 기준으로 상자도표(box plot) 확인
     - 사분위수 범위(Interquartile Range, IRQ)(제 1사분위 ~ 제 3사분위) * 1.5 한 값보다 작거나 크면 이상치로 판단
     - EX) 제 1사분위수 : 4, 제 3사분위수 : 20 일때, IRQ : 20 - 4 = 16 
     - 16 * 1.5 = 24
     - 이상값 : -20 보다 작거나 (4 - 24), 44(20 + 24)보다 큰값 
   - **정규분포**에서 크게 벗아난 데이터 확인
     - 분산(variance) 기준으로 정규분포 97.5%, 약 표준편차 2.5배 값
     - 우도(likelihood) 기준 우도값 범위 밖의 데이터
   - 데이터 간의 **거리 계산**으로 이상치 확인
     - 군집(clustering)
     - 밀도(density)
     - 이웃법(nearest neighbor)
<br>

2. 이상값(Outlier) 처리방법
   - 제거
   - 대체 : 보통은  최댓값으로 대체
   - 변환 
     - 단위 값이 클 때(멀리 퍼져있는 값 분포를 모을 때) 사용 Ex) 로그 변환, 제곱근
     - 전체 데이터에 영향을 주므로 의미가 있는지 유무를 판단해야할 필요 있음


---

<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">2. 변수선택</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.변수선택(Variable Selection)](#chapter-3)<br>


### **2-1. 변수선택(Variable Selection)** <a id="chapter-3"></a>

1. 필터 방법(Filter method)
  - 변수 하나씩 레이블(종속변수)와 관련이 있는가 확인 (상관분석)
  - Ex) 가족력 여부, 음주량, 흡연량, 운동량, 식단 등등 각 변수별로 암발생과 관련이 있는가?
2. 래퍼 방법(Wrapper method)
  - 모든 변수 중 유의한 영향 변수를 통계적 방법<b>(t-test, F-test)</b>으로 확인 (회귀분석)
    - 전진(Forward) 방법 : 변수를 모델에 넣으면서 유의한지 확인
    - 후진(Backward) 방법 : 변수를 모델에서 빼면서 유의한지 확인
    - 단계선택법(Stepwise) : 전진과 후진을 반복한 방법
  - Ex) 암발생을 예측하는 좋은 변수 1순위 : 가족력 여부 / 2순위 : 음주량 / 3순위 : 흡연량 / 4순위 : 스트레스 지수
3. 임베디드 방법(Embedded method)
  - 변수의 <b>가중치(계수)</b>를 매우 작게, 의미없는 변수의 가중치는 0으로 설정
    - 라소(Lasso)
    - 릿지(Ridge)
    - 엘리스틱넷(Elastic Net)

---

<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">3. 차원축소</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.차원축소](#chapter-4)<br>
- [2.종류](#chapter-5)<br>
- [3.장점 및 활용](#chapter-6)<br>

### **3-1. 차원축소** <a id="chapter-4"></a>
- 여러 변수들의 개수를 줄이는 방법. 차원은 변수를 의미함
- 차원축소는 직접 예측 혹은 분류의 목적에 활용되지는 않기 때문에 비지도 학습법. 다만 축소된 차원(변수)는 추후 예측이나 분류의 특성변수로 활용되기도 함
- 분석 전 변수 탐색의 목적이나 2차원 시각화의 목적으로 주로 활용
- 변수를 축양한 것이 더 좋은 예측/분류 결과를 가져오기도 함
<br>

### **3-2. 종류** <a id="chapter-5"></a>
1. 주성분 분석(Pricipal Component Analysis, PCA)
  - 원래 데이터 특징을 잘 설명해주는 성분을 추출하기 위하여 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법
  - 성분 1을 기준으로 분석 -> 90도(의미: 상관계수가 0) 회전 후 분석


2. 요인 분석(Factor Analysis)
  - 원래 데이터 특징을 잘 설명해주는 성분을 추출하기 위하여 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법
  - 사각회전 : 주성분 분석이 90도를 기준으로 분석한다면 사각회전을 통해 90도가 아닌 N도를 기준으로 분석(보다 더 현실적인 분석)


3. 독립성 분석(Independent Component Analysis, ICA)
  - 다변량의 신호를 통계적으로 독립적인 하부성분으로 분리하여 차원을 축소하는 기법


4. 다차원 척도법(Multi-Dimensional Scaling)
  - 개체들 사이의 유사성, 거리를 측정하여 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 방법

5. t-SNE(T-distributed stochastic neighbor embedding)
  - t-SNE는 데이터에서 지역 인접성(local neighborhoods)을 보존하려고 시도하는 차원축소 알고리즘. 2차원 또는 3차원으로 표현할 때 이용하며 차원을 줄이면서 다른 방법이 놓칠 수 있는 구조 파악에 활용

6. 특이값 분해(Singular Value Decomposition)
  - M x N 차원의 행렬 데이터에서 특이값을 추출하고 이를 통해 주어진 데이터 세트를 효과적으로 축약할 수 있는 기법
  - 상관계수를 활용


### **3-3. 장점과 활용** <a id="chapter-6"></a>

1. 장점
- 데이터 양이 줄어 분석시간이 줄어들고 저장변수가 감소되어 분석 작업에 유리
- 변수들 간의 상관을 우선 고려하여 차원을 축소하여 학습모델이 간단해지고 안정적인 결과 도출

2. 활용
- 탐색적 데이터 분석(EDA)의 목적으로 변수 혹은 케이스들 간의 상관을 시각적으로 도출 및 표현
- 분석 모델에서 투입되는 다양한 변수들 중 변수 추출
- 다차원 공간의 정보를 저차원으로 변환
- 데이터 내 중요 변수 혹은 잠재된 새로운 요인 발견

---

<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">4. 파생변수</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.파생변수](#chapter-7)<br>


### **4-1. 파생변수** <a id="chapter-7"></a>
- 파생변수는 기존 변수들을 이용해서 의미 있는 새롭게 만들어진 변수
- 파생변수가 더욱 좋은 분석 결과를 도출할 수 있음
- 분석경험, 데이터에 대한 이해 등 고수준의 지식과 경험이 요구됨

Ex)
단위 변환 : mile -> km
표현 방식 변환 : 주민등록번호 -> 나이, 성별 생성
요약 통계량 변환
  - 통신사 통화데이터 -> 특정지역의 시간별 유동인구 수
변수 결홥
  - 국어, 문학, 수학, 과학 -> 언어능력, 수리능력 축약

기존


|주민번호|가족수|연소득|대출|
|:-----|---:|---:|--:|
|880818-1******|1|4,200|0|
|661112-1******|3|7,800|30,000|
|740222-2******|4|5,600|20,000|


파생변수 생성


|성별|연령|연소득/1인|대출여부|
|--:|--:|------:|-----:|
|1|34|4,200|0|
|1|56|2,600|1|
|2|48|1,400|1|


---

<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">5. 변수 변환</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.변수변환 및 방법](#chapter-8)<br>
- [2.정규화](#chapter-9)<br>
- [3.원핫인코딩(One-Hot_Encoding)](#chapter-10)<br>


### **5-1. 변수변환 및 방법** <a id="chapter-8"></a>
- 분석에 더욱 적합하도록 기존의 변수를 새로운 기준으로 변환하는 방법
- 모든 분석에 기본이며, 머신러닝에서는 필수과정



|방법|설명 및 예시|
|:--:|:-------|
|구간화<br>(비닝:binning)|연령 -> 연령대|
|단위변환|연봉 -> log(연봉)|
|정규화<br>(normalization)|서로 다른 단위의 독립변수<br>-> 정규화로 통일|
|더미변수화<br>(Dummy,One-hot-encoding)|거주지(서울:1, 경기:2, 지방:3) 변수<br>-> 서울(0,1),경기(0,1),지방(0,1) 3개 변수로 나누어 구성|



기존


|성별|연령|연소득|생활비|
|--:|---:|---:|--:|
|1|34|4,200|120|
|2|40|5,600|480|


파생변수 생성

|구간화(연령대)|단위변환<br>(log(소득))|더미변환<br>(성별:남)|정규화<br>(연령)|정규화<br>(소득)|
|--:|---:|---:|--:|--|
|30대|3.6232|1|0.200|0.220|
|40대|3.7482|0|0.600|0.360|



### **5-2. 정규화** <a id="chapter-9"></a>
- 머신러닝 분석에 투입되는 특성변수들 간의 단위를 동일하게 조정하기 위한 과정
- 데이터 스케일링(Scaling)이라고도 함


1. **Min-Max Scaling** (분포 가능한 구간 0~1)
  - 가장 대표적인 머신러닝/딥러닝의 스케일링 방법
  - 각 변수특성의 값과 최소값의 차이를 (최대-최소)로 나눔
  - 이 경우 모든 값은 0 이상의 양(+)의 값을 가짐
  - 이상치에 영향이 있음
  - $Zi = \frac{Xi - Xmin}{Xmax - Xmin}$


2. Standardization
  - 표준화는 각 수치와 평균의 차이를 표준편차로 나눈 값
  - 평균이 0, 표준편차가 1이 되는 통계적인 자료 표준화의 대표적인 값
  - 일반적인 범위 이상인 매우 큰 음의 값이나 매우 큰 양의 값이 될 수도 있음
  - $Zi = \frac{Xi - \overline{X}}{\sigma_x}$



### **5-3. 원핫인코딩(One-Hot-Encoding)** <a id="chapter-10"></a>
- 범주형 특성변수를 0,1로 변경한 변수. 더미변수(Dummy Variable)
- 범주특성 집단수만큼 생성됨
- 1의 의미는 각 하위집단에 해당되는가(1), 아닌가(0)임



---

<div style="text-align: right;">
작성일자 : 2023-08-21<br>
</div>


## <span style="background-color:#FFF5b1">6. 불균형 데이터</span>
{: .d-inline-block }

Ver 0.1.1
{: .label .label-green }


- [1.불균형 데이터 처리](#chapter-11)<br>


### **6-1. 불균형 데이터 처리** <a id="chapter-11"></a>
- 범주형 종속변수의 비율에 <b><u>지나친 차이가 있는 데이터</u></b>
- Question : 정상 9,500명, 환자 500명 (95% : 5%)로 환자(질환)을 제대로 예측할 수 있을까?
  - 과소표집(Under Sampling) or 과대표집(Over Sampling)
  - 과소표집
    - 1. Random Under Sampling
    - 2. Tome Link Method : 분류선의 경계 근처에 있는(애매한) 샘플은 빼고 진행
    - 3. CNN(Condensed Nearest Neighbor)
    - 4. OSS(One Sided Selection)
  - 과대표집
    - 1. Random Over-Sampling
    - 2. SMOTE(Synthetic Minority Over-sampling TEchnique)
    - 3. Borderline-SMOTE(Condensed Nearest Neighbor)
    - 4. ADASYN(ADAptive SYNthetic)
